# Toxic Comment Identification using LSTM and Word Embeddings
- This model uses TensorFlow and Keras to perform text cleaning and create an LSTM network.
- This model is capable of detecting the extent of toxicity in 6 levels.
<ul>
  <li>Toxic</li>
  <li>Severe Toxic</li>
  <li>Identity hate</li>
  <li>Threat</li>
  <li>Insult</li>
</ul>

- The dataset used is a jigsaw toxic comment classification dataset from Kaggle

<p>The model works on the following type of data formats
  <ul>
    <li>Audio</li>
    <li>Audio from microphone</li>
    <li>Text</li>
    <li>Youtube video using url</li>
  </ul>
</p>

- Speech recognition is handled using assembly API

### Text Data
<img width="773" alt="text" src="https://github.com/mystrycodes/toxic_comment_detection/assets/97798007/997a14f6-1391-481b-bb5e-c9be0ed68bb9">

### Audio data
<img width="752" alt="audio" src="https://github.com/mystrycodes/toxic_comment_detection/assets/97798007/2e6cb59c-25cb-4bd2-8feb-959095c49450">

### Youtube Video
<img width="757" alt="youtube" src="https://github.com/mystrycodes/toxic_comment_detection/assets/97798007/fea228cd-d3fa-4db8-b01a-ce745a35900e">

### Microphone
<img width="760" alt="microphone" src="https://github.com/mystrycodes/toxic_comment_detection/assets/97798007/7b8853cb-4a24-48e8-97ee-a1de69e27b0c">

